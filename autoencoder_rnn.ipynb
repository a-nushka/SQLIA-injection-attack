{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HlZ739v5WB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd37a9f-5cde-4ade-8815-99df3cb0bbcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"/content/Modified_SQL_Dataset.csv\").dropna().drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7q0hc0cG6Dkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    # text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['Cleaned_Query'] = data['Query'].apply(preprocess_text)\n",
        "\n",
        "# Text vectorization\n",
        "vectorizer = CountVectorizer(min_df=2, max_df=0.7)\n",
        "posts = vectorizer.fit_transform(data['Cleaned_Query']).toarray()\n",
        "\n",
        "transformed_posts = pd.DataFrame(posts)\n",
        "data = pd.concat([data, transformed_posts], axis=1)\n",
        "\n",
        "X = data[data.columns[2:]]\n",
        "Y = data['Label']\n",
        "\n",
        "# Convert only numeric columns to float32\n",
        "numeric_columns = X.select_dtypes(include=['float32']).columns\n",
        "X[numeric_columns] = X[numeric_columns].astype('float32')\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
        "\n",
        "# Print data types and shapes for verification\n",
        "print(\"X_train data types:\")\n",
        "print(X_train.dtypes)\n",
        "print(\"\\nX_train shape:\", X_train.shape)\n",
        "\n",
        "print(\"\\ny_train data types:\")\n",
        "print(y_train.dtypes)\n",
        "print(\"\\ny_train shape:\", y_train.shape)\n",
        "\n",
        "print(\"\\nX_test data types:\")\n",
        "print(X_test.dtypes)\n",
        "print(\"\\nX_test shape:\", X_test.shape)\n",
        "\n",
        "print(\"\\ny_test data types:\")\n",
        "print(y_test.dtypes)\n",
        "print(\"\\ny_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "g5lKdKlC6MJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9227730-64b9-4957-b665-8c29f8a33300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train data types:\n",
            "Cleaned_Query    object\n",
            "0                 int64\n",
            "1                 int64\n",
            "2                 int64\n",
            "3                 int64\n",
            "                  ...  \n",
            "6713              int64\n",
            "6714              int64\n",
            "6715              int64\n",
            "6716              int64\n",
            "6717              int64\n",
            "Length: 6719, dtype: object\n",
            "\n",
            "X_train shape: (24725, 6719)\n",
            "\n",
            "y_train data types:\n",
            "int64\n",
            "\n",
            "y_train shape: (24725,)\n",
            "\n",
            "X_test data types:\n",
            "Cleaned_Query    object\n",
            "0                 int64\n",
            "1                 int64\n",
            "2                 int64\n",
            "3                 int64\n",
            "                  ...  \n",
            "6713              int64\n",
            "6714              int64\n",
            "6715              int64\n",
            "6716              int64\n",
            "6717              int64\n",
            "Length: 6719, dtype: object\n",
            "\n",
            "X_test shape: (6182, 6719)\n",
            "\n",
            "y_test data types:\n",
            "int64\n",
            "\n",
            "y_test shape: (6182,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#debug print lines\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LhH9k3YunTj",
        "outputId": "80600062-7a8b-498b-f35e-00bee3ff20ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (24725, 6719)\n",
            "X_test shape: (6182, 6719)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#debug prints\n",
        "print(X_train.dtypes)\n",
        "print(X_test.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSts3t-DvotJ",
        "outputId": "95f2100f-0448-477d-cf4e-875d632df1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned_Query    object\n",
            "0                 int64\n",
            "1                 int64\n",
            "2                 int64\n",
            "3                 int64\n",
            "                  ...  \n",
            "6713              int64\n",
            "6714              int64\n",
            "6715              int64\n",
            "6716              int64\n",
            "6717              int64\n",
            "Length: 6719, dtype: object\n",
            "Cleaned_Query    object\n",
            "0                 int64\n",
            "1                 int64\n",
            "2                 int64\n",
            "3                 int64\n",
            "                  ...  \n",
            "6713              int64\n",
            "6714              int64\n",
            "6715              int64\n",
            "6716              int64\n",
            "6717              int64\n",
            "Length: 6719, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude 'Cleaned_Query' column from input data\n",
        "X_train_numeric = X_train.drop(columns=['Cleaned_Query'])\n",
        "X_test_numeric = X_test.drop(columns=['Cleaned_Query'])\n",
        "\n",
        "# Autoencoder model\n",
        "input_dim = X_train_numeric.shape[1]\n",
        "encoding_dim = 64\n",
        "\n",
        "#autoencoder has 1 ip layer and 2 dense layers and 1 output layer\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "decoder_layer = Dense(input_dim, activation='relu')(encoder_layer)\n",
        "\n",
        "autoencoder = Model(input_layer, decoder_layer)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Fit the autoencoder model\n",
        "autoencoder.fit(X_train_numeric, X_train_numeric, epochs=25, batch_size=64, shuffle=True, validation_data=(X_test_numeric, X_test_numeric))\n",
        "\n",
        "encoder = Model(input_layer, encoder_layer)\n",
        "\n",
        "# Predict with the encoder model\n",
        "encoded_train = encoder.predict(X_train_numeric)\n",
        "encoded_test = encoder.predict(X_test_numeric)\n"
      ],
      "metadata": {
        "id": "Jjm86s0y6ORJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(encoding_dim, 1)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(encoded_train.reshape(encoded_train.shape[0], encoding_dim, 1), y_train, epochs=25, batch_size=64, validation_data=(encoded_test.reshape(encoded_test.shape[0], encoding_dim, 1), y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(encoded_test.reshape(encoded_test.shape[0], encoding_dim, 1), y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "FGZuRHzt6XtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making predictions on the test data\n",
        "predictions = model.predict(encoded_test.reshape(encoded_test.shape[0], encoding_dim, 1))\n",
        "\n",
        "# Convert the predicted probabilities to binary predictions (0 or 1)\n",
        "class_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Print the predicted class labels\n",
        "print(\"Predicted class labels:\", class_predictions)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, class_predictions)\n",
        "precision = precision_score(y_test, class_predictions)\n",
        "recall = recall_score(y_test, class_predictions)\n",
        "f1 = f1_score(y_test, class_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "DkhAMcMrGHeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "predictions = model.predict(encoded_test.reshape(encoded_test.shape[0], encoding_dim, 1))\n",
        "class_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, class_predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Malicious', 'Malicious'], yticklabels=['Non-Malicious', 'Malicious'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pfy4WkNPTro3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}